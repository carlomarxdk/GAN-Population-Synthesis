{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import math\n",
    "import torch.nn as nn \n",
    "from torch.nn.functional import leaky_relu, softmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import Counter\n",
    "\n",
    "from GANutils import *\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('Data/TU_onehot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = Counter([v.split('_')[0] for v in list(data.columns)])\n",
    "cat_total = sum(cat.values())\n",
    "cat_n = list(cat.values())\n",
    "INPUT_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_noise(size:int, batch_size:int):\n",
    "    '''\n",
    "    Generates a 1-d vector of gaussian sampled random values\n",
    "    '''\n",
    "    n = Variable(torch.randn([batch_size,size]))\n",
    "    return n\n",
    "\n",
    "\n",
    "\n",
    "def softmax2onehot(x):\n",
    "    x=x.to('cpu')\n",
    "    max_idx = torch.argmax(x, 1, keepdim=True)\n",
    "    one_hot = torch.FloatTensor(x.shape)\n",
    "    one_hot.zero_()\n",
    "    return one_hot.scatter_(1, max_idx, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator (nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_size: int, \n",
    "                 hidden_size: int, \n",
    "                 cat: Counter):\n",
    "        super(Generator, self).__init__()\n",
    "        self.cat = cat\n",
    "        self.cat_n = list(cat.values())\n",
    "        self.output_size = sum(self.cat.values())\n",
    "        \n",
    "        self.l1 = nn.Sequential( \n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.BatchNorm1d(hidden_size, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "        self.l2 = nn.Sequential( \n",
    "            nn.Linear(hidden_size, hidden_size * 2),\n",
    "            nn.LeakyReLU(negative_slope = 0.2),\n",
    "            nn.BatchNorm1d(hidden_size * 2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "        self.l3 = nn.Sequential( \n",
    "            nn.Linear(hidden_size*2, hidden_size),\n",
    "            nn.LeakyReLU(negative_slope = 0.2),\n",
    "            nn.BatchNorm1d(hidden_size * 3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "        self.out = nn.Sequential( \n",
    "            nn.Linear(hidden_size, self.output_size))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.l1(x)\n",
    "        x=self.l2(x)\n",
    "        x=self.l3(x)\n",
    "        x=self.out(x)\n",
    "        ### Sigmoid per class\n",
    "        x = x.split(self.cat_n, dim=1)\n",
    "        out = torch.cat([softmax(v, dim =1) for v in x], dim=1)\n",
    "        return out\n",
    "#G = Generator(input_size=INPUT_SIZE, hidden_size=1024, cat=cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size:int, output_size=1, vanila=False):\n",
    "        '''\n",
    "        input_size: size of the data\n",
    "        output_size: is always 1 \n",
    "        vanila: if True, Sigmoid is going to applied on the last layer\n",
    "        '''\n",
    "        super(Discriminator,self).__init__()\n",
    "        \n",
    "        self.l1 = nn.Sequential( \n",
    "            nn.Linear(input_size, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.l2 = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.l3 = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        if vanila:\n",
    "            self.out = nn.Sequential(\n",
    "                torch.nn.Linear(256, output_size),\n",
    "                torch.nn.Sigmoid()\n",
    "                )\n",
    "        else:\n",
    "            self.out = nn.Sequential(\n",
    "                torch.nn.Linear(256, output_size))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.l3(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN():\n",
    "    def __init__(self, \n",
    "                 data, \n",
    "                 cat, \n",
    "                 epochs = 1000,\n",
    "                 batch_size=32,             #bad\n",
    "                 gen_learn_rate=0.01,   #    0.05   0.05   0.01  \n",
    "                 disc_learn_rate=10E-9,\n",
    "                 vanila=False): #   10E+8  10E-9  10E-10\n",
    "        #Data\n",
    "        self.cat = cat\n",
    "        self.cat_n = list(cat.values())\n",
    "        self.onehot_size = sum(self.cat.values())\n",
    "        self.train_val_split(data, batch_size)\n",
    "        \n",
    "        #Networks\n",
    "        self.G = Generator(input_size=INPUT_SIZE, hidden_size=2048, cat=self.cat).to(device)\n",
    "        self.D = Discriminator(input_size=self.onehot_size, vanila=vanila).to(device)\n",
    "        \n",
    "        #Parameters\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.gen_learn_rate = gen_learn_rate\n",
    "        self.disc_learn_rate = disc_learn_rate\n",
    "        \n",
    "        #Optimizer\n",
    "        self.loss = nn.BCELoss()\n",
    "\n",
    "        ''''\n",
    "        ADAM optimizer does not give good results \n",
    "        \n",
    "        self.generator_optim = torch.optim.Adam(self.G.parameters(),\n",
    "                                                gen_learn_rate, \n",
    "                                                eps = 10E-8, \n",
    "                                                betas=(0.5, 0.999)) #0.6\n",
    "        self.discriminator_optim = torch.optim.Adam(self.D.parameters(), disc_learn_rate, betas=(0.4, 0.999))\n",
    "        '''\n",
    "        self.generator_optim = torch.optim.RMSprop(self.G.parameters(),\n",
    "                                                  lr = self.gen_learn_rate,\n",
    "                                                  centered=True)\n",
    "        self.discriminator_optim = torch.optim.RMSprop(self.D.parameters(),\n",
    "                                                      lr = self.disc_learn_rate,\n",
    "                                                      centered=True)\n",
    "        \n",
    "    def train_val_split(self, data, batch_size):\n",
    "        train, val = train_test_split(data, test_size=0.1)\n",
    "        self.train = DataLoader(torch.tensor(train.values), \n",
    "                                                batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "        self.val  = DataLoader(torch.tensor(val.values), \n",
    "                                                batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    def sample(self, n_samples: int):\n",
    "        '''\n",
    "        Generate the data data with Generator network\n",
    "        n_samples: usually equals to the batch size\n",
    "        '''\n",
    "        z = gen_noise(INPUT_SIZE, n_samples)\n",
    "        z = Variable(z, requires_grad=False).to(device)\n",
    "        return self.G.forward(z)\n",
    "    \n",
    "    def discriminator_train_step(self, x):\n",
    "        '''\n",
    "        x: set of real data \n",
    "        '''\n",
    "        batch_size = x.shape[0]\n",
    "        x_fake = self.sample(batch_size)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def fit(self):\n",
    "        self.discriminator_loss, self.generator_loss = [], []\n",
    "        for epoch in range(self.epochs):\n",
    "            batch_d_loss, batch_g_loss = [], []\n",
    "            for x in self.val:\n",
    "                if(cuda): x.to(device)\n",
    "                batch_size = x.shape[0]\n",
    "                # True data is given label 1, while fake data is given label 0\n",
    "                true_label = torch.ones(batch_size, 1).to(device)\n",
    "                fake_label = torch.zeros(batch_size, 1).to(device)\n",
    "        \n",
    "                self.D.zero_grad()\n",
    "                self.G.zero_grad()\n",
    "                \n",
    "                # Step 0. First error propgation through Generator\n",
    "                x_fake = self.sample(batch_size)\n",
    "                x_fake = x_fake.split(self.cat_n, dim=1)\n",
    "                x_fake = torch.cat([softmax2onehot(v) for v in x_fake], dim=1)\n",
    "                x_fake = x_fake.to(device)\n",
    "                \n",
    "                output = self.D.forward(x_fake)\n",
    "                error_generator = self.loss(output, true_label)\n",
    "                error_generator.backward()\n",
    "                self.generator_optim.step()\n",
    "                self.D.zero_grad()\n",
    "                self.G.zero_grad()\n",
    "        \n",
    "                \n",
    "        \n",
    "                # Step 1. Send real data through discriminator\n",
    "                #         and backpropagate its errors.\n",
    "                x_true = Variable(x).float()\n",
    "                if cuda: x_true = x_true.to(device)\n",
    "                output = self.D.forward(x_true)\n",
    "        \n",
    "                error_true = self.loss(output, true_label)\n",
    "                error_true.backward()\n",
    "        \n",
    "                # Step 2. Generate fake data G(z), where z ~ N(0, 1)\n",
    "                #         is a latent code.\n",
    "                x_fake = self.sample(batch_size)\n",
    "                x_fake = x_fake.split(self.cat_n, dim=1)\n",
    "                x_fake = torch.cat([softmax2onehot(v) for v in x_fake], dim=1)\n",
    "                x_fake = x_fake.to(device)\n",
    "                # Step 3. Send fake data through discriminator\n",
    "                #         propagate error and update D weights.\n",
    "                # --------------------------------------------\n",
    "                # Note: detach() is used to avoid compounding generator gradients\n",
    "                output = self.D.forward(x_fake.detach()) \n",
    "        \n",
    "                error_fake = self.loss(output, fake_label)\n",
    "                error_fake.backward()\n",
    "                self.discriminator_optim.step()\n",
    "                \n",
    "                # Step 4. Send fake data through discriminator _again_\n",
    "                #         propagate the error of the generator and\n",
    "                #         update G weights.\n",
    "                output = self.D.forward(x_fake)\n",
    "        \n",
    "                error_generator = self.loss(output, true_label)\n",
    "                error_generator.backward()\n",
    "                self.generator_optim.step()\n",
    "        \n",
    "                batch_d_loss.append(((error_true + error_fake)/2).item())\n",
    "                batch_g_loss.append(error_generator.item())\n",
    "            \n",
    "            self.discriminator_loss.append(np.mean(batch_d_loss))\n",
    "            self.generator_loss.append(np.mean(batch_g_loss))\n",
    "            \n",
    "            \n",
    "            clear_output()\n",
    "            print(\"Epoch: %3d || D Loss: %5.5f || G Loss: %5.5f \" %(epoch, np.mean(batch_d_loss), np.mean(batch_g_loss)))\n",
    "\n",
    "            # -- Plotting --\n",
    "            f, axarr = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "            # Loss\n",
    "            axarr[0].set_xlabel('Epoch')\n",
    "            axarr[0].set_ylabel('Loss')\n",
    "            axarr[0].set_title('Discriminator Loss || lr= %s' %self.disc_learn_rate )\n",
    "            axarr[1].set_xlabel('Epoch')\n",
    "            axarr[1].set_ylabel('Loss')\n",
    "            axarr[1].set_title('Generator Loss  || lr= %s' %self.gen_learn_rate )\n",
    "\n",
    "            axarr[0].plot(np.arange(epoch+1), self.discriminator_loss)\n",
    "            axarr[1].plot(np.arange(epoch+1), self.generator_loss, linestyle=\"--\")\n",
    "            plt.show()\n",
    "        def print_out(self):\n",
    "            pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:3606: FutureWarning: SparseDataFrame is deprecated and will be removed in a future version.\n",
      "Use a regular DataFrame whose columns are SparseArrays instead.\n",
      "\n",
      "See http://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html#migrating for more.\n",
      "\n",
      "  result = self._constructor(new_data).__finalize__(self)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-263-19393b17a841>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-262-bb71c22014a5>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, cat, epochs, batch_size, gen_learn_rate, disc_learn_rate, vanila)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#Networks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mINPUT_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monehot_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvanila\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvanila\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "gan = GAN(data = data, cat = cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
